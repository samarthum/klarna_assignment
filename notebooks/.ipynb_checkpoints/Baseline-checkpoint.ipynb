{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29825b87",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8428bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be48b43",
   "metadata": {},
   "source": [
    "**Read Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf64cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is separated by semicolon rather than the usual comma\n",
    "\n",
    "df = pd.read_csv('../data/dataset.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f15a87",
   "metadata": {},
   "source": [
    "**Data Exploration and checks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6211f8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>default</th>\n",
       "      <th>account_amount_added_12_24m</th>\n",
       "      <th>account_days_in_dc_12_24m</th>\n",
       "      <th>account_days_in_rem_12_24m</th>\n",
       "      <th>account_days_in_term_12_24m</th>\n",
       "      <th>account_incoming_debt_vs_paid_0_24m</th>\n",
       "      <th>account_status</th>\n",
       "      <th>account_worst_status_0_3m</th>\n",
       "      <th>account_worst_status_12_24m</th>\n",
       "      <th>...</th>\n",
       "      <th>status_3rd_last_archived_0_24m</th>\n",
       "      <th>status_max_archived_0_6_months</th>\n",
       "      <th>status_max_archived_0_12_months</th>\n",
       "      <th>status_max_archived_0_24_months</th>\n",
       "      <th>recovery_debt</th>\n",
       "      <th>sum_capital_paid_account_0_12m</th>\n",
       "      <th>sum_capital_paid_account_12_24m</th>\n",
       "      <th>sum_paid_inv_0_12m</th>\n",
       "      <th>time_hours</th>\n",
       "      <th>worst_status_active_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63f69b2c-8b1c-4740-b78d-52ed9a4515ac</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178839</td>\n",
       "      <td>9.653333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e961183-8c15-4470-9a5e-07a1bd207661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49014</td>\n",
       "      <td>13.181389</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d8edaae6-4368-44e0-941e-8328f203e64e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124839</td>\n",
       "      <td>11.561944</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0095dfb6-a886-4e2a-b056-15ef45fdb0ef</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>324676</td>\n",
       "      <td>15.751111</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c8f8b835-5647-4506-bf15-49105d8af30b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7100</td>\n",
       "      <td>12.698611</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uuid  default  account_amount_added_12_24m  \\\n",
       "0  63f69b2c-8b1c-4740-b78d-52ed9a4515ac      0.0                            0   \n",
       "1  0e961183-8c15-4470-9a5e-07a1bd207661      0.0                            0   \n",
       "2  d8edaae6-4368-44e0-941e-8328f203e64e      0.0                            0   \n",
       "3  0095dfb6-a886-4e2a-b056-15ef45fdb0ef      0.0                            0   \n",
       "4  c8f8b835-5647-4506-bf15-49105d8af30b      0.0                            0   \n",
       "\n",
       "   account_days_in_dc_12_24m  account_days_in_rem_12_24m  \\\n",
       "0                        0.0                         0.0   \n",
       "1                        0.0                         0.0   \n",
       "2                        0.0                         0.0   \n",
       "3                        NaN                         NaN   \n",
       "4                        0.0                         0.0   \n",
       "\n",
       "   account_days_in_term_12_24m  account_incoming_debt_vs_paid_0_24m  \\\n",
       "0                          0.0                                  0.0   \n",
       "1                          0.0                                  NaN   \n",
       "2                          0.0                                  NaN   \n",
       "3                          NaN                                  NaN   \n",
       "4                          0.0                                  NaN   \n",
       "\n",
       "   account_status  account_worst_status_0_3m  account_worst_status_12_24m  \\\n",
       "0             1.0                        1.0                          NaN   \n",
       "1             1.0                        1.0                          1.0   \n",
       "2             NaN                        NaN                          NaN   \n",
       "3             NaN                        NaN                          NaN   \n",
       "4             NaN                        NaN                          NaN   \n",
       "\n",
       "   ...  status_3rd_last_archived_0_24m  status_max_archived_0_6_months  \\\n",
       "0  ...                               1                               1   \n",
       "1  ...                               1                               1   \n",
       "2  ...                               1                               1   \n",
       "3  ...                               1                               1   \n",
       "4  ...                               0                               1   \n",
       "\n",
       "   status_max_archived_0_12_months  status_max_archived_0_24_months  \\\n",
       "0                                1                                1   \n",
       "1                                2                                2   \n",
       "2                                2                                2   \n",
       "3                                1                                1   \n",
       "4                                1                                1   \n",
       "\n",
       "   recovery_debt sum_capital_paid_account_0_12m  \\\n",
       "0              0                              0   \n",
       "1              0                              0   \n",
       "2              0                              0   \n",
       "3              0                              0   \n",
       "4              0                              0   \n",
       "\n",
       "  sum_capital_paid_account_12_24m  sum_paid_inv_0_12m  time_hours  \\\n",
       "0                               0              178839    9.653333   \n",
       "1                               0               49014   13.181389   \n",
       "2                               0              124839   11.561944   \n",
       "3                               0              324676   15.751111   \n",
       "4                               0                7100   12.698611   \n",
       "\n",
       "   worst_status_active_inv  \n",
       "0                      1.0  \n",
       "1                      NaN  \n",
       "2                      1.0  \n",
       "3                      1.0  \n",
       "4                      NaN  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa3f111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99976 entries, 0 to 99975\n",
      "Data columns (total 43 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   uuid                                 99976 non-null  object \n",
      " 1   default                              89976 non-null  float64\n",
      " 2   account_amount_added_12_24m          99976 non-null  int64  \n",
      " 3   account_days_in_dc_12_24m            88140 non-null  float64\n",
      " 4   account_days_in_rem_12_24m           88140 non-null  float64\n",
      " 5   account_days_in_term_12_24m          88140 non-null  float64\n",
      " 6   account_incoming_debt_vs_paid_0_24m  40661 non-null  float64\n",
      " 7   account_status                       45603 non-null  float64\n",
      " 8   account_worst_status_0_3m            45603 non-null  float64\n",
      " 9   account_worst_status_12_24m          33215 non-null  float64\n",
      " 10  account_worst_status_3_6m            42274 non-null  float64\n",
      " 11  account_worst_status_6_12m           39626 non-null  float64\n",
      " 12  age                                  99976 non-null  int64  \n",
      " 13  avg_payment_span_0_12m               76140 non-null  float64\n",
      " 14  avg_payment_span_0_3m                50671 non-null  float64\n",
      " 15  merchant_category                    99976 non-null  object \n",
      " 16  merchant_group                       99976 non-null  object \n",
      " 17  has_paid                             99976 non-null  bool   \n",
      " 18  max_paid_inv_0_12m                   99976 non-null  float64\n",
      " 19  max_paid_inv_0_24m                   99976 non-null  float64\n",
      " 20  name_in_email                        99976 non-null  object \n",
      " 21  num_active_div_by_paid_inv_0_12m     77037 non-null  float64\n",
      " 22  num_active_inv                       99976 non-null  int64  \n",
      " 23  num_arch_dc_0_12m                    99976 non-null  int64  \n",
      " 24  num_arch_dc_12_24m                   99976 non-null  int64  \n",
      " 25  num_arch_ok_0_12m                    99976 non-null  int64  \n",
      " 26  num_arch_ok_12_24m                   99976 non-null  int64  \n",
      " 27  num_arch_rem_0_12m                   99976 non-null  int64  \n",
      " 28  num_arch_written_off_0_12m           81898 non-null  float64\n",
      " 29  num_arch_written_off_12_24m          81898 non-null  float64\n",
      " 30  num_unpaid_bills                     99976 non-null  int64  \n",
      " 31  status_last_archived_0_24m           99976 non-null  int64  \n",
      " 32  status_2nd_last_archived_0_24m       99976 non-null  int64  \n",
      " 33  status_3rd_last_archived_0_24m       99976 non-null  int64  \n",
      " 34  status_max_archived_0_6_months       99976 non-null  int64  \n",
      " 35  status_max_archived_0_12_months      99976 non-null  int64  \n",
      " 36  status_max_archived_0_24_months      99976 non-null  int64  \n",
      " 37  recovery_debt                        99976 non-null  int64  \n",
      " 38  sum_capital_paid_account_0_12m       99976 non-null  int64  \n",
      " 39  sum_capital_paid_account_12_24m      99976 non-null  int64  \n",
      " 40  sum_paid_inv_0_12m                   99976 non-null  int64  \n",
      " 41  time_hours                           99976 non-null  float64\n",
      " 42  worst_status_active_inv              30461 non-null  float64\n",
      "dtypes: bool(1), float64(19), int64(19), object(4)\n",
      "memory usage: 32.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d357262e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>account_amount_added_12_24m</th>\n",
       "      <th>account_days_in_dc_12_24m</th>\n",
       "      <th>account_days_in_rem_12_24m</th>\n",
       "      <th>account_days_in_term_12_24m</th>\n",
       "      <th>account_incoming_debt_vs_paid_0_24m</th>\n",
       "      <th>account_status</th>\n",
       "      <th>account_worst_status_0_3m</th>\n",
       "      <th>account_worst_status_12_24m</th>\n",
       "      <th>account_worst_status_3_6m</th>\n",
       "      <th>...</th>\n",
       "      <th>status_3rd_last_archived_0_24m</th>\n",
       "      <th>status_max_archived_0_6_months</th>\n",
       "      <th>status_max_archived_0_12_months</th>\n",
       "      <th>status_max_archived_0_24_months</th>\n",
       "      <th>recovery_debt</th>\n",
       "      <th>sum_capital_paid_account_0_12m</th>\n",
       "      <th>sum_capital_paid_account_12_24m</th>\n",
       "      <th>sum_paid_inv_0_12m</th>\n",
       "      <th>time_hours</th>\n",
       "      <th>worst_status_active_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>89976.000000</td>\n",
       "      <td>9.997600e+04</td>\n",
       "      <td>88140.000000</td>\n",
       "      <td>88140.000000</td>\n",
       "      <td>88140.000000</td>\n",
       "      <td>40661.000000</td>\n",
       "      <td>45603.000000</td>\n",
       "      <td>45603.000000</td>\n",
       "      <td>33215.000000</td>\n",
       "      <td>42274.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>99976.000000</td>\n",
       "      <td>99976.000000</td>\n",
       "      <td>99976.000000</td>\n",
       "      <td>99976.000000</td>\n",
       "      <td>99976.000000</td>\n",
       "      <td>99976.000000</td>\n",
       "      <td>99976.000000</td>\n",
       "      <td>9.997600e+04</td>\n",
       "      <td>99976.000000</td>\n",
       "      <td>30461.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.014315</td>\n",
       "      <td>1.225515e+04</td>\n",
       "      <td>0.223043</td>\n",
       "      <td>5.044622</td>\n",
       "      <td>0.286896</td>\n",
       "      <td>1.331292</td>\n",
       "      <td>1.042168</td>\n",
       "      <td>1.172905</td>\n",
       "      <td>1.337348</td>\n",
       "      <td>1.185291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744299</td>\n",
       "      <td>0.800582</td>\n",
       "      <td>1.052233</td>\n",
       "      <td>1.226164</td>\n",
       "      <td>4.035429</td>\n",
       "      <td>10816.065386</td>\n",
       "      <td>6542.895325</td>\n",
       "      <td>3.920880e+04</td>\n",
       "      <td>15.329780</td>\n",
       "      <td>1.121762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.118786</td>\n",
       "      <td>3.548148e+04</td>\n",
       "      <td>5.808117</td>\n",
       "      <td>22.863971</td>\n",
       "      <td>2.929910</td>\n",
       "      <td>26.482299</td>\n",
       "      <td>0.202713</td>\n",
       "      <td>0.420142</td>\n",
       "      <td>0.575043</td>\n",
       "      <td>0.443309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634912</td>\n",
       "      <td>0.719946</td>\n",
       "      <td>0.786121</td>\n",
       "      <td>0.833502</td>\n",
       "      <td>163.934564</td>\n",
       "      <td>26463.972170</td>\n",
       "      <td>19041.223585</td>\n",
       "      <td>9.064929e+04</td>\n",
       "      <td>5.031360</td>\n",
       "      <td>0.343660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.600000e+03</td>\n",
       "      <td>11.622708</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.599500e+04</td>\n",
       "      <td>15.792778</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.937250e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.662952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9029.750000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>4.384425e+04</td>\n",
       "      <td>19.542014</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.128775e+06</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>3914.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>36479.000000</td>\n",
       "      <td>571475.000000</td>\n",
       "      <td>341859.000000</td>\n",
       "      <td>2.962870e+06</td>\n",
       "      <td>23.999722</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            default  account_amount_added_12_24m  account_days_in_dc_12_24m  \\\n",
       "count  89976.000000                 9.997600e+04               88140.000000   \n",
       "mean       0.014315                 1.225515e+04                   0.223043   \n",
       "std        0.118786                 3.548148e+04                   5.808117   \n",
       "min        0.000000                 0.000000e+00                   0.000000   \n",
       "25%        0.000000                 0.000000e+00                   0.000000   \n",
       "50%        0.000000                 0.000000e+00                   0.000000   \n",
       "75%        0.000000                 4.937250e+03                   0.000000   \n",
       "max        1.000000                 1.128775e+06                 365.000000   \n",
       "\n",
       "       account_days_in_rem_12_24m  account_days_in_term_12_24m  \\\n",
       "count                88140.000000                 88140.000000   \n",
       "mean                     5.044622                     0.286896   \n",
       "std                     22.863971                     2.929910   \n",
       "min                      0.000000                     0.000000   \n",
       "25%                      0.000000                     0.000000   \n",
       "50%                      0.000000                     0.000000   \n",
       "75%                      0.000000                     0.000000   \n",
       "max                    365.000000                    97.000000   \n",
       "\n",
       "       account_incoming_debt_vs_paid_0_24m  account_status  \\\n",
       "count                         40661.000000    45603.000000   \n",
       "mean                              1.331292        1.042168   \n",
       "std                              26.482299        0.202713   \n",
       "min                               0.000000        1.000000   \n",
       "25%                               0.000000        1.000000   \n",
       "50%                               0.152082        1.000000   \n",
       "75%                               0.662952        1.000000   \n",
       "max                            3914.000000        4.000000   \n",
       "\n",
       "       account_worst_status_0_3m  account_worst_status_12_24m  \\\n",
       "count               45603.000000                 33215.000000   \n",
       "mean                    1.172905                     1.337348   \n",
       "std                     0.420142                     0.575043   \n",
       "min                     1.000000                     1.000000   \n",
       "25%                     1.000000                     1.000000   \n",
       "50%                     1.000000                     1.000000   \n",
       "75%                     1.000000                     2.000000   \n",
       "max                     4.000000                     4.000000   \n",
       "\n",
       "       account_worst_status_3_6m  ...  status_3rd_last_archived_0_24m  \\\n",
       "count               42274.000000  ...                    99976.000000   \n",
       "mean                    1.185291  ...                        0.744299   \n",
       "std                     0.443309  ...                        0.634912   \n",
       "min                     1.000000  ...                        0.000000   \n",
       "25%                     1.000000  ...                        0.000000   \n",
       "50%                     1.000000  ...                        1.000000   \n",
       "75%                     1.000000  ...                        1.000000   \n",
       "max                     4.000000  ...                        5.000000   \n",
       "\n",
       "       status_max_archived_0_6_months  status_max_archived_0_12_months  \\\n",
       "count                    99976.000000                     99976.000000   \n",
       "mean                         0.800582                         1.052233   \n",
       "std                          0.719946                         0.786121   \n",
       "min                          0.000000                         0.000000   \n",
       "25%                          0.000000                         1.000000   \n",
       "50%                          1.000000                         1.000000   \n",
       "75%                          1.000000                         1.000000   \n",
       "max                          3.000000                         5.000000   \n",
       "\n",
       "       status_max_archived_0_24_months  recovery_debt  \\\n",
       "count                     99976.000000   99976.000000   \n",
       "mean                          1.226164       4.035429   \n",
       "std                           0.833502     163.934564   \n",
       "min                           0.000000       0.000000   \n",
       "25%                           1.000000       0.000000   \n",
       "50%                           1.000000       0.000000   \n",
       "75%                           2.000000       0.000000   \n",
       "max                           5.000000   36479.000000   \n",
       "\n",
       "       sum_capital_paid_account_0_12m  sum_capital_paid_account_12_24m  \\\n",
       "count                    99976.000000                     99976.000000   \n",
       "mean                     10816.065386                      6542.895325   \n",
       "std                      26463.972170                     19041.223585   \n",
       "min                          0.000000                         0.000000   \n",
       "25%                          0.000000                         0.000000   \n",
       "50%                          0.000000                         0.000000   \n",
       "75%                       9029.750000                        85.000000   \n",
       "max                     571475.000000                    341859.000000   \n",
       "\n",
       "       sum_paid_inv_0_12m    time_hours  worst_status_active_inv  \n",
       "count        9.997600e+04  99976.000000             30461.000000  \n",
       "mean         3.920880e+04     15.329780                 1.121762  \n",
       "std          9.064929e+04      5.031360                 0.343660  \n",
       "min          0.000000e+00      0.000278                 1.000000  \n",
       "25%          2.600000e+03     11.622708                 1.000000  \n",
       "50%          1.599500e+04     15.792778                 1.000000  \n",
       "75%          4.384425e+04     19.542014                 1.000000  \n",
       "max          2.962870e+06     23.999722                 3.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b6f61",
   "metadata": {},
   "source": [
    "We will create separate lists for the categorical and the numeric column names. We could do this by using df.select_dtypes but in this problem, I'd rather specify the feature names from the problem statement itself for clarity of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be657556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'a': 1, 'b': 2, 'c': 3}\n",
    "pd.DataFrame(a, index=[0]).values[0][[0, 2, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42d5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From problem description \n",
    "\n",
    "categorical_cols = ['default', 'account_status', 'account_worst_status_0_3m', 'account_worst_status_12_24m',\n",
    "                    'account_worst_status_3_6m', 'account_worst_status_6_12m', 'merchant_category',\n",
    "                    'merchant_group', 'name_in_email', 'status_last_archived_0_24m', \n",
    "                    'status_2nd_last_archived_0_24m', 'status_3rd_last_archived_0_24m',\n",
    "                    'status_max_archived_0_6_months', 'status_max_archived_0_12_months',\n",
    "                    'status_max_archived_0_24_months', 'worst_status_active_inv', 'has_paid']\n",
    "\n",
    "numeric_cols = df.drop(categorical_cols, axis=1).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00de6dc9",
   "metadata": {},
   "source": [
    "Let's first set aside the test data in order to avoid any sort of bias. The test data consists of the rows where the 'default' column is missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67b691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[df['default'].isnull()].drop(['uuid', 'default'], axis=1)\n",
    "train = df.dropna(subset=['default'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8571c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('../data/test.csv', index=False)\n",
    "train.to_csv('../data/train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d3c57f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['default']\n",
    "train = train.drop(['uuid', 'default'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce07f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the test data: (10000, 41)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the test data:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba58d0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data: (89976, 41)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the training data:', train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75171dd8",
   "metadata": {},
   "source": [
    "Ideally, for the remainder of the project we will not look at the test data. We will do all of our data exploration and modelling on the train data itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511d007",
   "metadata": {},
   "source": [
    "**The target variable** <br>\n",
    "The goal here is to build a model that can predict the probability of a loan default given a set of features. Before we get into more EDA and model building, we'll do a quick exploration of the target variable, or the dependent variable, 'default'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fcdc14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.985685\n",
       "1.0    0.014315\n",
       "Name: default, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target.value_counts().plot(kind='bar');\n",
    "display(target.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e21acec",
   "metadata": {},
   "source": [
    "As expected in such problems, the target variable is heavily imbalanced. The defaults occur only **1.43%** of the times. \n",
    "We can either treat this as an **imbalanced classification** problem, or we can treat it as an **anomaly detection** problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad5a434",
   "metadata": {},
   "source": [
    "Before diving into further data exploration, let's quickly train a model and try to get an idea of feature importances from it. We can then do deep dives into individual features, and maybe engineer a few features as well.\n",
    "\n",
    "For that, we will first have to take care of the missing values, as well as the categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af30bd68",
   "metadata": {},
   "source": [
    "**Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "466059ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst_status_active_inv                0.695074\n",
       "account_worst_status_12_24m            0.667456\n",
       "account_worst_status_6_12m             0.603639\n",
       "account_incoming_debt_vs_paid_0_24m    0.593014\n",
       "account_worst_status_3_6m              0.577243\n",
       "account_status                         0.543856\n",
       "account_worst_status_0_3m              0.543856\n",
       "avg_payment_span_0_3m                  0.493265\n",
       "avg_payment_span_0_12m                 0.238597\n",
       "num_active_div_by_paid_inv_0_12m       0.229595\n",
       "num_arch_written_off_0_12m             0.181215\n",
       "num_arch_written_off_12_24m            0.181215\n",
       "account_days_in_dc_12_24m              0.118732\n",
       "account_days_in_rem_12_24m             0.118732\n",
       "account_days_in_term_12_24m            0.118732\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get sub-dataframe of just the missing columns\n",
    "\n",
    "missing = train.isnull().mean()\n",
    "cols_with_missing = missing[missing > 0].index\n",
    "\n",
    "display(missing[missing > 0].sort_values(ascending=False))\n",
    "\n",
    "missing = train[cols_with_missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e983c78",
   "metadata": {},
   "source": [
    "For the purposes of this baseline model, we will just **drop the columns which have missing values**. \n",
    "Since we are straight up dropping the columns, it won't matter whether we do this after a train-validation split or before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2d4e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_cols(df, cols):\n",
    "    return df.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = drop_missing_cols(train, cols_with_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d8254ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('merchant_category', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88e72602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89976, 40)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43d954a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_COLUMNS = train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5b4a7f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final columns used\n",
    "\n",
    "with open('../models/final_columns.pkl','wb') as file:\n",
    "    pickle.dump(FINAL_COLUMNS, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e7ee4",
   "metadata": {},
   "source": [
    "The number of columns have reduced from 42 to 26 after dropping the columns with missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c5bbc3",
   "metadata": {},
   "source": [
    "**Create a train-validation split** <br>\n",
    "Before we proceed further, this would be a good point to create a train-validation split and continue pre-processing this smaller training data. \n",
    "Since the number of data points vs. features is fairly high, we will go ahead with a train-val split rather than cross-validation (at least for this baseline model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "91a27fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1de7405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (71980, 40)\n",
      "Validation data shape: (17996, 40)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape:', X_train.shape)\n",
    "print('Validation data shape:', X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e48026",
   "metadata": {},
   "source": [
    "**Categorical Columns** <br>\n",
    "We know that models require us to convert variables where the categorical variables aren't encoded as numbers. This can be done either through Label Encoding or One Hot Encoding. \n",
    "For this baseline approach, we will just OHE all the categorical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3827c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract DF of categorical columns\n",
    "cat_cols_final = [col for col in categorical_cols if col in X_train.columns]\n",
    "cat_df_train = X_train[cat_cols_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9cc154a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_status</th>\n",
       "      <th>account_worst_status_0_3m</th>\n",
       "      <th>account_worst_status_12_24m</th>\n",
       "      <th>account_worst_status_3_6m</th>\n",
       "      <th>account_worst_status_6_12m</th>\n",
       "      <th>merchant_group</th>\n",
       "      <th>name_in_email</th>\n",
       "      <th>status_last_archived_0_24m</th>\n",
       "      <th>status_2nd_last_archived_0_24m</th>\n",
       "      <th>status_3rd_last_archived_0_24m</th>\n",
       "      <th>status_max_archived_0_6_months</th>\n",
       "      <th>status_max_archived_0_12_months</th>\n",
       "      <th>status_max_archived_0_24_months</th>\n",
       "      <th>worst_status_active_inv</th>\n",
       "      <th>has_paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25564</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clothing &amp; Shoes</td>\n",
       "      <td>F+L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42077</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Nick</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47940</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>F+L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       account_status  account_worst_status_0_3m  account_worst_status_12_24m  \\\n",
       "25564             1.0                        1.0                          NaN   \n",
       "42077             NaN                        NaN                          NaN   \n",
       "47940             1.0                        1.0                          1.0   \n",
       "\n",
       "       account_worst_status_3_6m  account_worst_status_6_12m  \\\n",
       "25564                        1.0                         1.0   \n",
       "42077                        NaN                         NaN   \n",
       "47940                        1.0                         1.0   \n",
       "\n",
       "         merchant_group name_in_email  status_last_archived_0_24m  \\\n",
       "25564  Clothing & Shoes           F+L                           1   \n",
       "42077   Health & Beauty          Nick                           1   \n",
       "47940     Home & Garden           F+L                           1   \n",
       "\n",
       "       status_2nd_last_archived_0_24m  status_3rd_last_archived_0_24m  \\\n",
       "25564                               1                               1   \n",
       "42077                               0                               0   \n",
       "47940                               1                               1   \n",
       "\n",
       "       status_max_archived_0_6_months  status_max_archived_0_12_months  \\\n",
       "25564                               1                                2   \n",
       "42077                               1                                1   \n",
       "47940                               2                                2   \n",
       "\n",
       "       status_max_archived_0_24_months  worst_status_active_inv  has_paid  \n",
       "25564                                2                      NaN      True  \n",
       "42077                                1                      NaN      True  \n",
       "47940                                2                      1.0      True  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb4c53ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical columns: 15\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of categorical columns: {cat_df_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fbc02aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "account_status                      4\n",
       "account_worst_status_0_3m           4\n",
       "account_worst_status_12_24m         4\n",
       "account_worst_status_3_6m           4\n",
       "account_worst_status_6_12m          4\n",
       "merchant_group                     12\n",
       "name_in_email                       8\n",
       "status_last_archived_0_24m          5\n",
       "status_2nd_last_archived_0_24m      5\n",
       "status_3rd_last_archived_0_24m      5\n",
       "status_max_archived_0_6_months      4\n",
       "status_max_archived_0_12_months     5\n",
       "status_max_archived_0_24_months     5\n",
       "worst_status_active_inv             3\n",
       "has_paid                            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get count of unique values in each column so that we understand how our dataframe will expand upon OHE\n",
    "cat_df_train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761255ba",
   "metadata": {},
   "source": [
    "The 'merchant_category' column will cause our dataframe to explode and contain too many columns. For the purposes of this baseline approach, we will just drop that column and instead use the 'merchant_group' as a fairly good proxy for the 'merchant_category' problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "158d00aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_CAT_COLS = cat_df_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6fc754b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "ohe_data = ohe.fit_transform(cat_df_train)\n",
    "cat_df_train = pd.DataFrame(ohe_data, columns=ohe.get_feature_names_out()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0f84b158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of categorical data after OHE: (71980, 80)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of categorical data after OHE: {cat_df_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27a0a52",
   "metadata": {},
   "source": [
    "We now have converted our categorical columns into the right data format in order to feed it to an ML model. We will combine the numeric dataframe with the categorical one to get our entire training DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "226f9afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = FINAL_CAT_COLS\n",
    "numeric_cols = list(set(FINAL_COLUMNS) - set(FINAL_CAT_COLS))\n",
    "\n",
    "cat_df = X_train[categorical_cols]\n",
    "numeric_df = X_train[numeric_cols]\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "ohe_data = ohe.fit_transform(cat_df)\n",
    "cat_df = pd.DataFrame(ohe_data, columns=ohe.get_feature_names_out(), index=cat_df.index).astype(int)\n",
    "\n",
    "X_train = pd.concat([numeric_df, cat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "391ba2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE for X_val\n",
    "cat_df_val = X_val[categorical_cols]\n",
    "numeric_df_val = X_val[numeric_cols]\n",
    "\n",
    "ohe_data = ohe.transform(cat_df_val)\n",
    "cat_df_val = pd.DataFrame(ohe_data, columns=ohe.get_feature_names_out(), index=cat_df_val.index).astype(int)\n",
    "\n",
    "X_val = pd.concat([numeric_df_val, cat_df_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e24c852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape after OHE: (71980, 105)\n",
      "Validation data shape after OHE: (17996, 105)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train data shape after OHE: {X_train.shape}')\n",
    "print(f'Validation data shape after OHE: {X_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac1d48f",
   "metadata": {},
   "source": [
    "**PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58feb517",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca_data_train = pca.fit_transform(X_train)\n",
    "pca_data_valid = pca.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48749e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Explained Variance: {round(pca.explained_variance_ratio_.sum(), 4) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b4213",
   "metadata": {},
   "source": [
    "**Model Building and Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8639ea58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution in train data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.985746\n",
       "1.0    0.014254\n",
       "Name: default, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution in validation data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.985441\n",
       "1.0    0.014559\n",
       "Name: default, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quickly check target variable distribution in train and validation data\n",
    "print('Target distribution in train data')\n",
    "display(y_train.value_counts(normalize=True))\n",
    "\n",
    "print('Target distribution in validation data')\n",
    "display(y_val.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6221e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(random_state=1)\n",
    "#model = RandomForestClassifier(n_estimators=250, n_jobs=-1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7bee466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:18:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on train data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e312cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for train and test data:\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_val = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbda024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "print('Model performance on training data:\\n')\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(f'ROC AUC Score: {round(roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c242c",
   "metadata": {},
   "source": [
    "This simple basline model is performing quite well on the training data. Let's look at the validation data to see if this is due to some overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "print('Model performance on validation data:\\n')\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(f'ROC AUC Score: {round(roc_auc_score(y_val, model.predict_proba(X_val)[:, 1]), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123539f9",
   "metadata": {},
   "source": [
    "The model is clearly overfitting on our data. For now, we won't concern ourselves with improving the results of this model since the purpose of this activity is to just build an end-to-end pipeline that functions from an engineering standpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150cfcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=True).tail(10).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877418c",
   "metadata": {},
   "source": [
    "**Let's see the performance on the PCA data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(pca_data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for train and test data:\n",
    "y_pred_train = model.predict(pca_data_train)\n",
    "y_pred_val = model.predict(pca_data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508939c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "print('Model performance on training data:\\n')\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(f'ROC AUC Score: {round(roc_auc_score(y_train, model.predict_proba(pca_data_train)[:, 1]), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16398ea1",
   "metadata": {},
   "source": [
    "This simple basline model is performing quite well on the training data. Let's look at the validation data to see if this is due to some overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd666eac",
   "metadata": {},
   "source": [
    "We're observing that this is not making too much of a difference either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7112d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "print('Model performance on validation data:\\n')\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(f'ROC AUC Score: {round(roc_auc_score(y_val, model.predict_proba(pca_data_valid)[:, 1]), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a469ea",
   "metadata": {},
   "source": [
    "For our experiments, let's define a function that evaluates the given model on our train and validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "46dff118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, X_train, X_val):\n",
    "    model = XGBClassifier(random_state=1)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Get predictions for train and test data:\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Model evaluation on training data\n",
    "    print('Model performance on training data:\\n')\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    print(f'ROC AUC Score: {round(roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]), 2)}')\n",
    "    \n",
    "    # Model evaluation on validation data\n",
    "    print('Model performance on validation data:\\n')\n",
    "    print(classification_report(y_val, y_pred_val))\n",
    "    print(f'ROC AUC Score: {round(roc_auc_score(y_val, model.predict_proba(X_val)[:, 1]), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba01fa48",
   "metadata": {},
   "source": [
    "**Dealing with the class imbalance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc7fca6",
   "metadata": {},
   "source": [
    "We will try out different methods of dealing with the oversampling and see how it changes the model outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921396ae",
   "metadata": {},
   "source": [
    "**Random Oversampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0de8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(X_resampled, y_resampled, X_train, X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9af2b4",
   "metadata": {},
   "source": [
    "**SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665dbabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44256b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cdfd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(X_resampled, y_resampled, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3049d3e",
   "metadata": {},
   "source": [
    "**ADASYN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afb12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn = ADASYN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dffdb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1113181",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d35ec",
   "metadata": {},
   "source": [
    "**Random Undersampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5c3cdc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c0a34ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bbde6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "59715b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:19:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7affc918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:19:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Model performance on training data:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.88      0.94     70954\n",
      "         1.0       0.11      0.95      0.19      1026\n",
      "\n",
      "    accuracy                           0.88     71980\n",
      "   macro avg       0.55      0.92      0.56     71980\n",
      "weighted avg       0.99      0.88      0.93     71980\n",
      "\n",
      "ROC AUC Score: 0.97\n",
      "Model performance on validation data:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.88      0.93     17734\n",
      "         1.0       0.08      0.73      0.15       262\n",
      "\n",
      "    accuracy                           0.88     17996\n",
      "   macro avg       0.54      0.81      0.54     17996\n",
      "weighted avg       0.98      0.88      0.92     17996\n",
      "\n",
      "ROC AUC Score: 0.9\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X_resampled, y_resampled, X_train, X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cabed9",
   "metadata": {},
   "source": [
    "On this undersampled data, our model is finally not overfitting too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "57ea9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train the model on entire data and save it\n",
    "X = pd.concat([X_train, X_val])\n",
    "y = pd.concat([y_train, y_val])\n",
    "\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a4a26f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = XGBClassifier(random_state=1)\n",
    "final_model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54256e50",
   "metadata": {},
   "source": [
    "**Save model and other variables as .pkl files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "390101dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "\n",
    "with open('../models/xgboost.pkl', 'wb') as file:\n",
    "    pickle.dump(final_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "55ccc81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the one hot encoder\n",
    "\n",
    "with open('../models/ohe.pkl', 'wb') as file:\n",
    "    pickle.dump(ohe, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6015482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the categorical and numeric columns as well\n",
    "\n",
    "with open('../models/cat_cols.pkl', 'wb') as file:\n",
    "    pickle.dump(categorical_cols, file)\n",
    "    \n",
    "with open('../models/num_cols.pkl', 'wb') as file:\n",
    "    pickle.dump(numeric_cols, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4d3f04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model columns after OHE\n",
    "\n",
    "model_cols = X_train.columns.tolist()\n",
    "\n",
    "with open('../models/model_cols.pkl', 'wb') as file:\n",
    "    pickle.dump(model_cols, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
